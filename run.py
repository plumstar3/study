# run.py (å®Œå…¨æœ€çµ‚ç‰ˆ)

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, losses, callbacks
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr

# ==============================================================================
# 1. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼é–¢é€£
# ==============================================================================
def load_and_preprocess_data(path='./Data/soybean_samples.csv'):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€åŸºæœ¬çš„ãªå‰å‡¦ç†ï¼ˆæ¨™æº–åŒ–ãªã©ï¼‰ã‚’è¡Œã†ã€‚"""
    if not os.path.exists(path):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return None
    df = pd.read_csv(path)
    
    feature_cols = df.columns[3:]
    train_df = df[df['year'] <= 2017]
    mean = train_df[feature_cols].mean()
    std = train_df[feature_cols].std()
    std[std == 0] = 1.0
    df[feature_cols] = (df[feature_cols] - mean) / std
    df = df.fillna(0)
    df = df[df['yield'] >= 5].reset_index(drop=True)
    return df

def create_year_loc_dict_and_avg(df):
    """å¹´ã¨åœ°åŸŸ(loc_ID)ã‚’ã‚­ãƒ¼ã«ã—ãŸãƒ‡ãƒ¼ã‚¿è¾æ›¸ã¨ã€å¹´ã”ã¨ã®å¹³å‡åé‡è¾æ›¸ã‚’ä½œæˆã™ã‚‹ã€‚"""
    loc_year_dict = { (row.loc_ID, int(row.year)): row for index, row in df.iterrows() }
    avg_yield_by_year = df.groupby('year')['yield'].mean()
    mean_yield = avg_yield_by_year.mean()
    std_yield = avg_yield_by_year.std()
    avg_dict = (avg_yield_by_year - mean_yield) / std_yield
    
    if 2018 not in avg_dict.index and 2017 in avg_dict.index:
        avg_dict[2018] = avg_dict.get(2017, 0)
        
    return loc_year_dict, {str(k): v for k, v in avg_dict.to_dict().items()}

class SoybeanDataGenerator(tf.keras.utils.Sequence):
    """Kerasãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ï¼ˆåœ°åŸŸè€ƒæ…®ãƒ»TimeDistributedå¯¾å¿œç‰ˆï¼‰"""
    def __init__(self, df, loc_year_dict, avg_dict, batch_size, is_training=True):
        self.loc_year_dict = loc_year_dict
        self.avg_dict = avg_dict
        self.batch_size = batch_size
        
        self.sequences = []
        loc_ids = df['loc_ID'].unique()
        all_years = sorted(df['year'].unique())

        for loc_id in loc_ids:
            for i in range(len(all_years) - 4):
                seq_years = all_years[i:i+5]
                if all((loc_id, year) in self.loc_year_dict for year in seq_years):
                    self.sequences.append({'loc_id': loc_id, 'years': seq_years})
        
        if is_training:
            self.sequences = [s for s in self.sequences if 2018 not in s['years']]
        else:
            self.sequences = [s for s in self.sequences if 2018 in s['years']]
        
        print(f"{'è¨“ç·´' if is_training else 'æ¤œè¨¼'}ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãŒã€{len(self.sequences)}å€‹ã®æœ‰åŠ¹ãªã€Œåœ°åŸŸ-5å¹´ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        self.indices = np.arange(len(self.sequences))
        self.on_epoch_end()

    def __len__(self):
        if len(self.sequences) == 0: return 0
        return int(np.floor(len(self.sequences) / self.batch_size))

    def __getitem__(self, index):
        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]
        batch_seq_info = [self.sequences[i] for i in batch_indices]
        actual_batch_size = len(batch_seq_info)

        # âœ¨å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã§æº–å‚™
        X_dict = {
            'e_input': np.zeros((actual_batch_size, 5, 312)),
            's_input': np.zeros((actual_batch_size, 5, 66)),
            'p_input': np.zeros((actual_batch_size, 5, 14)),
            'ybar_input': np.zeros((actual_batch_size, 5, 1))
        }
        Y_dict = {
            'Yhat1': np.zeros((actual_batch_size, 1)),
            'Yhat2': np.zeros((actual_batch_size, 4, 1))
        }

        for i, seq_info in enumerate(batch_seq_info):
            loc_id = seq_info['loc_id']
            years = seq_info['years']
            
            for j, year in enumerate(years):
                sample = self.loc_year_dict[(loc_id, year)]
                features = sample.iloc[3:].values # ID, year, yieldã‚’é™¤ã
                
                # ç‰¹å¾´é‡ã‚’å„å…¥åŠ›ã«å‰²ã‚Šå½“ã¦
                X_dict['e_input'][i, j, :] = features[0:312]
                X_dict['s_input'][i, j, :] = features[312:378]
                X_dict['p_input'][i, j, :] = features[378:392]
                X_dict['ybar_input'][i, j, 0] = self.avg_dict[str(year)]

            Y_dict['Yhat1'][i] = self.loc_year_dict[(loc_id, years[-1])]['yield']
            past_yields = [self.loc_year_dict[(loc_id, y)]['yield'] for y in years[:-1]]
            Y_dict['Yhat2'][i] = np.array(past_yields).reshape(4, 1)

        return X_dict, Y_dict

    def on_epoch_end(self):
        np.random.shuffle(self.indices)

# ==============================================================================
# 2. ãƒ¢ãƒ‡ãƒ«å®šç¾©
# ==============================================================================
def create_cnn_block(input_layer, filters, kernel_sizes):
    """æ±ç”¨çš„ãªCNNãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆ"""
    x = input_layer
    for f, k in zip(filters, kernel_sizes):
        x = layers.Conv1D(f, k, activation='relu', padding='same')(x)
        x = layers.MaxPooling1D(pool_size=2, strides=1, padding='same')(x) # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã‚’èª¿æ•´
    return layers.Flatten()(x)

def build_and_compile_model():
    # --- å…¥åŠ›å±¤ã®å®šç¾© (æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦) ---
    e_input = layers.Input(shape=(5, 312), name="e_input")
    s_input = layers.Input(shape=(5, 66), name="s_input")
    p_input = layers.Input(shape=(5, 14), name="p_input")
    ybar_input = layers.Input(shape=(5, 1), name="ybar_input")

    # --- CNNãƒ–ãƒ­ãƒƒã‚¯ã®å®šç¾© (ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦) ---
    e_proc_input = layers.Input(shape=(312,), name="e_proc_input")
    e_reshaped = layers.Reshape((6, 52))(e_proc_input)
    e_cnn_outs = [create_cnn_block(e_reshaped[:, i, :, None], [8, 16], [3, 3]) for i in range(6)]
    e_cnn_model = models.Model(inputs=e_proc_input, outputs=layers.Concatenate()(e_cnn_outs), name="E_CNN_Model")
    
    s_proc_input = layers.Input(shape=(66,), name="s_proc_input")
    s_reshaped = layers.Reshape((6, 11))(s_proc_input)
    s_cnn_out = create_cnn_block(s_reshaped, [16, 32], [3, 3])
    s_cnn_model = models.Model(inputs=s_proc_input, outputs=s_cnn_out, name="S_CNN_Model")

    # --- TimeDistributedã§å„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã«CNNã‚’é©ç”¨ ---
    e_processed = layers.TimeDistributed(e_cnn_model, name="TDD_E_CNN")(e_input)
    s_processed = layers.TimeDistributed(s_cnn_model, name="TDD_S_CNN")(s_input)
    p_processed = layers.TimeDistributed(layers.Flatten(), name="TDD_P_Flatten")(p_input)

    # --- å…¨ã¦ã®ç‰¹å¾´é‡ã‚’çµåˆ ---
    merged = layers.Concatenate()([e_processed, s_processed, p_processed, ybar_input])
    
    # --- LSTMå±¤ ---
    x = layers.Dense(128, activation='relu')(merged) # LSTMå‰ã®æ¬¡å…ƒåœ§ç¸®
    x = layers.LSTM(64, return_sequences=True, dropout=0.2)(x)
    output = layers.TimeDistributed(layers.Dense(1))(x)
    
    Yhat1 = layers.Identity(name='Yhat1')(output[:, -1, :])
    Yhat2 = layers.Identity(name='Yhat2')(output[:, :-1, :])

    model = models.Model(inputs=[e_input, s_input, p_input, ybar_input], outputs=[Yhat1, Yhat2])
    
    # âœ¨ã€æœ€çµ‚ä¿®æ­£ã€‘ lossã¨metricsã‚’è¾æ›¸å½¢å¼ã§æŒ‡å®šã™ã‚‹
    model.compile(optimizer=optimizers.Adam(learning_rate=0.0003),
                  loss={'Yhat1': losses.Huber(), 'Yhat2': losses.Huber()},
                  loss_weights={'Yhat1': 1.0, 'Yhat2': 0.0},
                  metrics={'Yhat1': 'mae'})
    return model

# ==============================================================================
# 3. è¨“ç·´ã¨è©•ä¾¡
# ==============================================================================
def run_training_and_evaluation():
    print("\nğŸ› ï¸ ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™...")
    df = load_and_preprocess_data()
    if df is None: return

    loc_year_dict, avg_dict = create_year_loc_dict_and_avg(df)
    
    train_generator = SoybeanDataGenerator(df, loc_year_dict, avg_dict, batch_size=32, is_training=True)
    val_generator = SoybeanDataGenerator(df, loc_year_dict, avg_dict, batch_size=26, is_training=False)

    model = build_and_compile_model()
    model.summary(line_length=120)

    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)

    if len(val_generator) > 0:
        model.fit(
            train_generator,
            validation_data=val_generator,
            epochs=200,
            callbacks=[early_stop],
            verbose=2
        )
    else:
        print("\næ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€æ¤œè¨¼ãªã—ã§è¨“ç·´ã—ã¾ã™ã€‚")
        model.fit(train_generator, epochs=200, callbacks=[callbacks.EarlyStopping(monitor='loss', patience=20)])
        
    model.save("soybean_yield_model.keras")
    print("\nâœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†ãƒ»ä¿å­˜æ¸ˆã¿")

    print("\nğŸ” ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™...")
    if len(val_generator) > 0:
        val_generator.on_epoch_end = lambda: None
        
        loaded_model = models.load_model("soybean_yield_model.keras")
        print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

        # å…¨ã¦ã®æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ä¸€åº¦ã«äºˆæ¸¬
        predictions = loaded_model.predict(val_generator)
        Y1_pred = predictions[0] # æœ€åˆã®å‡ºåŠ›ãŒYhat1
        
        # å…¨ã¦ã®æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‹ã‚‰å–å¾—
        Y1_test_true = np.concatenate([val_generator[i][1]['Yhat1'] for i in range(len(val_generator))])
        
        rmse = np.sqrt(mean_squared_error(Y1_test_true, Y1_pred))
        print(f"\nğŸ“Š Test RMSE (final year): {rmse:.4f}")

        if len(Y1_test_true) >= 2:
            corr, _ = pearsonr(Y1_test_true.flatten(), Y1_pred.flatten())
            print(f"ğŸ“ˆ ç›¸é–¢ä¿‚æ•° (final year): {corr:.4f}")

        np.savez("prediction_result.npz", Y1_true=Y1_test_true, Y1_pred=Y1_pred)
        print("ğŸ“ äºˆæ¸¬çµæœã‚’ 'prediction_result.npz' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    else:
        print("è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

# ==============================================================================
# 4. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯
# ==============================================================================
if __name__ == "__main__":
    print("ğŸŒ± å¤§è±†åé‡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« - ç·åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    run_training_and_evaluation()
    print("\nğŸ‰ å…¨å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")